{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from parse_xml_annotations import *\n",
    "from reinforcement import *\n",
    "from metrics import *\n",
    "from features import *\n",
    "from PIL import Image\n",
    "import random\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pid_map_image.txt', 'rb') as f:\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    data = u.load()\n",
    "# for k, _ in enumerate(roidb):\n",
    "#     roidb[k]['image'] =  os.path.join(os.getcwd(), '/'.join(roidb[k]['image'].split('/')[5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_subregion = float(3)/4\n",
    "scale_mask = float(1)/(scale_subregion*4)\n",
    "replay = []\n",
    "h = 0\n",
    "buffer_experience_replay = 1000\n",
    "reward=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(10776, 1)\n",
      "[[ 0.18628812]\n",
      " [ 0.32921845]\n",
      " [ 0.31390208]\n",
      " ..., \n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "1\n",
      "(10776, 1)\n",
      "[[ 0.27941975]\n",
      " [ 0.40466195]\n",
      " [ 0.26671895]\n",
      " ..., \n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "2\n",
      "(10776, 1)\n",
      "[[ 0.23606631]\n",
      " [ 0.40666956]\n",
      " [ 0.2670961 ]\n",
      " ..., \n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "3\n",
      "(10776, 1)\n",
      "[[ 0.17810456]\n",
      " [ 0.50084829]\n",
      " [ 0.33183503]\n",
      " ..., \n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "4\n",
      "(10776, 1)\n",
      "[[ 0.15912551]\n",
      " [ 0.26796705]\n",
      " [ 0.20006512]\n",
      " ..., \n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "5\n",
      "(10776, 1)\n",
      "[[ 0.18522516]\n",
      " [ 0.2112546 ]\n",
      " [ 0.19421135]\n",
      " ..., \n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "6\n",
      "(10776, 1)\n",
      "[[ 0.18962294]\n",
      " [ 0.36071432]\n",
      " [ 0.26621214]\n",
      " ..., \n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "7\n",
      "(10776, 1)\n",
      "[[ 0.29220316]\n",
      " [ 0.33899677]\n",
      " [ 0.42536509]\n",
      " ..., \n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "8\n",
      "(10776, 1)\n",
      "[[ 0.18579939]\n",
      " [ 0.38536283]\n",
      " [ 0.30417132]\n",
      " ..., \n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n",
      "9\n",
      "(10776, 1)\n",
      "[[ 0.16391769]\n",
      " [ 0.44235829]\n",
      " [ 0.26640981]\n",
      " ..., \n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#import model\n",
    "\n",
    "class ModelController(object):\n",
    "\n",
    "    def __init__(self, data, pretrained_model=None, batch_size=32):\n",
    "        \"\"\"Initialize the SolverWrapper.\"\"\"\n",
    "        self.data = data\n",
    "        self.num_data = len(self.data)\n",
    "        self.batch_size = batch_size\n",
    "        self.pretrained_model=pretrained_model\n",
    "        \n",
    "        #tf.reset_default_graph()\n",
    "        #self.images_placeholder = tf.placeholder(tf.float32, shape=(1,224,224,3))\n",
    "        #self.my_feature_map_extractor_model = model.get_feature_map_extractor_model(self.images_placeholder, None, None, is_training=False)\n",
    "        \n",
    "        #self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "        \n",
    "        self.rl_model = build_model()\n",
    "        \n",
    "    def load_feature_map_model(self, checkpoint_path):\n",
    "        path_vgg = \"./vgg16_weights.h5\"\n",
    "        self.feature_map_extractor_model = obtain_compiled_vgg_16(path_vgg)\n",
    "        \n",
    "    def get_next_minibatch(self):\n",
    "        l = []\n",
    "        inds = np.random.choice(range(self.num_data), self.batch_size, replace=False)\n",
    "        for i in inds:\n",
    "            node = np.random.choice(range(len(self.data[i])), 2)\n",
    "            l.append([\n",
    "                [i, self.data[i][node[0]]],\n",
    "                [i, self.data[i][node[1]]]\n",
    "            ])\n",
    "        return l\n",
    "    \n",
    "    def save_model(self):\n",
    "        print('\\nsave model')\n",
    "        string = './models/model' + str(t) + '_epoch_' + str(i) + '.h5'\n",
    "        string2 = './models/model' + str(t) + '.h5'\n",
    "        self.rl_model.save_weights(string, overwrite=True)\n",
    "        self.rl_model.save_weights(string2, overwrite=True)\n",
    "\n",
    "    def train_model(self, max_iters=10, number_of_steps=10):\n",
    "        for i in range(max_iters):\n",
    "            print(i)\n",
    "            nodes = self.get_next_minibatch()\n",
    "            for node in nodes:\n",
    "                pid = node[0][0]\n",
    "                target_data = node[0][1]\n",
    "                search_data = node[1][1]\n",
    "\n",
    "                masked = 0\n",
    "                not_finished = 1\n",
    "\n",
    "                target_image = np.array(Image.open(target_data['image']))\n",
    "                bbox = target_data['boxes'][np.where(target_data['gt_pids']==pid)[0][0]]\n",
    "                target_image = target_image[bbox[1]:bbox[3],bbox[0]:bbox[2]]\n",
    "\n",
    "                search_image = np.array(Image.open(search_data['image']))\n",
    "                annotation = search_data['boxes'][np.where(search_data['gt_pids']==pid)[0][0]].reshape(1,-1).astype(np.int32)\n",
    "                gt_masks = generate_bounding_box_from_annotation(annotation, search_image.shape)\n",
    "                region_mask = np.ones([search_image.shape[0], search_image.shape[1]])\n",
    "                shape_gt_masks = np.shape(gt_masks)\n",
    "                array_classes_gt_objects = np.array([pid])\n",
    "                available_objects = np.ones(np.size(array_classes_gt_objects))\n",
    "\n",
    "                gt_mask = gt_masks[:, :, 0]\n",
    "                step = 0\n",
    "                new_iou = 0\n",
    "                last_matrix = np.zeros([1])\n",
    "                region_image = search_image\n",
    "                offset = (0, 0)\n",
    "                size_mask = (search_image.shape[0], search_image.shape[1])\n",
    "                original_shape = size_mask\n",
    "                old_region_mask = region_mask\n",
    "                region_mask = np.ones([search_image.shape[0], search_image.shape[1]])\n",
    "\n",
    "                iou, new_iou, last_matrix, index = follow_iou(gt_masks, region_mask, array_classes_gt_objects,\n",
    "                                pid, last_matrix, available_objects)\n",
    "                new_iou = iou\n",
    "                gt_mask = gt_masks[:, :, index]\n",
    "                # init of the history vector that indicates past actions (6 actions * 4 steps in the memory)\n",
    "                history_vector = np.zeros([24])\n",
    "                # computation of the initial state\n",
    "                search_iv = get_image_vector(region_image, self.feature_map_extractor_model)\n",
    "                target_iv = get_image_vector(target_image, self.feature_map_extractor_model)\n",
    "                state = get_state(target_iv, search_iv, history_vector)\n",
    "                print(state.shape)\n",
    "                print(state)\n",
    "                # status indicates whether the agent is still alive and has not triggered the terminal action\n",
    "                status = 1\n",
    "                action = 0\n",
    "                reward = 0\n",
    "                if step > number_of_steps:\n",
    "                    #background = draw_sequences(i, k, step, action, draw, region_image, background,\n",
    "                                                #path_testing_folder, iou, reward, gt_mask, region_mask, image_name,\n",
    "                                                #bool_draw)\n",
    "                    step += 1\n",
    "\n",
    "                while (status == 1) & (step < number_of_steps) & not_finished:\n",
    "                   # category = int(array_classes_gt_objects[0]-1)\n",
    "                    qval = self.rl_model.predict(state.T, batch_size=1)\n",
    "    #                     background = draw_sequences(i, k, step, action, draw, region_image, background,\n",
    "    #                                                 path_testing_folder, iou, reward, gt_mask, region_mask, image_name,\n",
    "    #                                                 bool_draw)\n",
    "                    step += 1\n",
    "                    # we force terminal action in case actual IoU is higher than 0.5, to train faster the agent\n",
    "                    if (i < 100) & (new_iou > 0.5):\n",
    "                        action = 6\n",
    "                    # epsilon-greedy policy\n",
    "                    elif random.random() < 0.1:\n",
    "                        action = np.random.randint(1, 7)\n",
    "                    else:\n",
    "                        action = (np.argmax(qval))+1\n",
    "\n",
    "                    # terminal action\n",
    "                    if action == 6:\n",
    "                        iou, new_iou, last_matrix, index = follow_iou(gt_masks, region_mask,\n",
    "                                                                      array_classes_gt_objects, pid,\n",
    "                                                                      last_matrix, available_objects)\n",
    "                        gt_mask = gt_masks[:, :, index]\n",
    "                        reward = get_reward_trigger(new_iou)\n",
    "#                         background = draw_sequences(i, k, step, action, draw, region_image, background,\n",
    "#                                                     path_testing_folder, iou, reward, gt_mask, region_mask,\n",
    "#                                                     image_name, bool_draw)\n",
    "                        step += 1\n",
    "                    # movement action, we perform the crop of the corresponding subregion\n",
    "                    else:\n",
    "                        region_mask = np.zeros(original_shape)\n",
    "                        size_mask = (size_mask[0] * scale_subregion, size_mask[1] * scale_subregion)\n",
    "                        if action == 1:\n",
    "                            offset_aux = (0, 0)\n",
    "                        elif action == 2:\n",
    "                            offset_aux = (0, size_mask[1] * scale_mask)\n",
    "                            offset = (offset[0], offset[1] + size_mask[1] * scale_mask)\n",
    "                        elif action == 3:\n",
    "                            offset_aux = (size_mask[0] * scale_mask, 0)\n",
    "                            offset = (offset[0] + size_mask[0] * scale_mask, offset[1])\n",
    "                        elif action == 4:\n",
    "                            offset_aux = (size_mask[0] * scale_mask, \n",
    "                                          size_mask[1] * scale_mask)\n",
    "                            offset = (offset[0] + size_mask[0] * scale_mask,\n",
    "                                      offset[1] + size_mask[1] * scale_mask)\n",
    "                        elif action == 5:\n",
    "                            offset_aux = (size_mask[0] * scale_mask / 2,\n",
    "                                          size_mask[0] * scale_mask / 2)\n",
    "                            offset = (offset[0] + size_mask[0] * scale_mask / 2,\n",
    "                                      offset[1] + size_mask[0] * scale_mask / 2)\n",
    "                        region_image = region_image[int(offset_aux[0]):int(offset_aux[0]) + int(size_mask[0]),\n",
    "                                       int(offset_aux[1]):int(offset_aux[1]) + int(size_mask[1])]\n",
    "                        region_mask[int(offset[0]):int(offset[0]) + int(size_mask[0]), int(offset[1]):int(offset[1]) + int(size_mask[1])] = 1\n",
    "                        iou, new_iou, last_matrix, index = follow_iou(gt_masks, region_mask,\n",
    "                                                                      array_classes_gt_objects, pid,\n",
    "                                                                      last_matrix, available_objects)\n",
    "                        gt_mask = gt_masks[:, :, index]\n",
    "                        reward = get_reward_movement(iou, new_iou)\n",
    "                        iou = new_iou\n",
    "                    history_vector = update_history_vector(history_vector, action)\n",
    "                    #new_state = get_state(region_image, history_vector, self.feature_map_extractor_model)\n",
    "                    search_iv = get_image_vector(region_image, self.feature_map_extractor_model)\n",
    "                    new_state = get_state(target_iv, search_iv, history_vector)\n",
    "                    # Experience replay storage\n",
    "                    if len(replay) < buffer_experience_replay:\n",
    "                        replay.append((state, action, reward, new_state))\n",
    "                    else:\n",
    "                        if h < (buffer_experience_replay-1):\n",
    "                            h += 1\n",
    "                        else:\n",
    "                            h = 0\n",
    "                        h_aux = h\n",
    "                        h_aux = int(h_aux)\n",
    "                        replay[h_aux] = (state, action, reward, new_state)\n",
    "                        minibatch = random.sample(replay, batch_size)\n",
    "                        X_train = []\n",
    "                        y_train = []\n",
    "                        # we pick from the replay memory a sampled minibatch and generate the training samples\n",
    "                        for memory in minibatch:\n",
    "                            old_state, action, reward, new_state = memory\n",
    "                            old_qval = model.predict(old_state.T, batch_size=1)\n",
    "                            newQ = model.predict(new_state.T, batch_size=1)\n",
    "                            maxQ = np.max(newQ)\n",
    "                            y = np.zeros([1, 6])\n",
    "                            y = old_qval\n",
    "                            y = y.T\n",
    "                            if action != 6: #non-terminal state\n",
    "                                update = (reward + (gamma * maxQ))\n",
    "                            else: #terminal state\n",
    "                                update = reward\n",
    "                            y[action-1] = update #target output\n",
    "                            X_train.append(old_state)\n",
    "                            y_train.append(y)\n",
    "                        X_train = np.array(X_train)\n",
    "                        y_train = np.array(y_train)\n",
    "                        X_train = X_train.astype(\"float32\")\n",
    "                        y_train = y_train.astype(\"float32\")\n",
    "                        X_train = X_train[:, :, 0]\n",
    "                        y_train = y_train[:, :, 0]\n",
    "                        hist = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=1, verbose=0)\n",
    "                        models[0][category] = model\n",
    "                        state = new_state\n",
    "                    if action == 6:\n",
    "                        status = 0\n",
    "                        masked = 1\n",
    "                        sys.stdout.write('\\r'+str(j)+'/'+str(np.size(image_names))+'  step:'+str(step))\n",
    "                        # we mask object found with ground-truth so that agent learns faster\n",
    "                        image = mask_image_with_mean_background(gt_mask, image)\n",
    "                    else:\n",
    "                        masked = 0\n",
    "                available_objects[index] = 0\n",
    "        if (i+1)%1000 is 0:\n",
    "            self.save_model()\n",
    "            \n",
    "ct = ModelController(data, pretrained_model=None, batch_size=1)\n",
    "ct.load_feature_map_model('./resnet_v1_50.ckpt')\n",
    "ct.get_next_minibatch()\n",
    "ct.train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
